{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../data/raw_analyst_ratings.csv\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set summary\n",
    "print(\"INFO:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSample rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a53e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "# headlinke length\n",
    "df[\"headline_length\"] = df[\"headline\"].str.len()\n",
    "print(df[\"headline_length\"].describe())\n",
    "# plot\n",
    "df[\"headline_length\"].plot(kind=\"hist\", bins=40, figsize=(8,5),\n",
    "                           title=\"Headline Length Distribution\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.show()\n",
    "# publisher analysis\n",
    "publisher_counts = df[\"publisher\"].value_counts()\n",
    "\n",
    "print(\"Top Publishers:\")\n",
    "print(publisher_counts.head(10))\n",
    "# plot\n",
    "publisher_counts.head(10).plot(kind=\"bar\", figsize=(10,5),\n",
    "                               title=\"Top 10 Publishers\")\n",
    "plt.xlabel(\"Publisher\")\n",
    "plt.ylabel(\"Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series analysis\n",
    "daily_counts = df.set_index(\"date\").resample(\"D\").size()\n",
    "\n",
    "daily_counts.plot(figsize=(12,5), title=\"Daily Article Frequency\")\n",
    "plt.ylabel(\"Articles\")\n",
    "plt.show()\n",
    "# day of week\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "df[\"day_of_week\"].value_counts().reindex([\n",
    "    \"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"\n",
    "]).plot(kind=\"bar\", figsize=(10,5),\n",
    "        title=\"Articles by Day of Week\")\n",
    "\n",
    "plt.ylabel(\"Articles\")\n",
    "plt.show()\n",
    "# hour of day\n",
    "df[\"hour\"] = df[\"date\"].dt.hour\n",
    "\n",
    "df[\"hour\"].value_counts().sort_index().plot(kind=\"bar\", figsize=(12,5),\n",
    "                                            title=\"Articles by Hour of Day\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")   \n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2620ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nlp tokenaization and lemmatization\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [t for t in tokens if t.isalpha()]       # keep letters only\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "df[\"tokens\"] = df[\"headline\"].apply(clean_text)\n",
    "\n",
    "df[[\"headline\", \"tokens\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top keywords\n",
    "from collections import Counter\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for token_list in df[\"tokens\"]:\n",
    "    all_words.extend(token_list)\n",
    "\n",
    "keyword_counts = Counter(all_words).most_common(20)\n",
    "\n",
    "pd.DataFrame(keyword_counts, columns=[\"keyword\", \"count\"]).plot(\n",
    "    x=\"keyword\", y=\"count\", kind=\"bar\", figsize=(12,5),\n",
    "    title=\"Most Common Keywords\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
